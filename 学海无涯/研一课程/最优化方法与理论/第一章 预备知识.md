# 第一章 预备知识

## 一、最优化问题的定义

最优化问题的一般形式为
$$
\left.\begin{aligned}&min f(\vec{x})\\s.t.&s(\vec{x})\geq 0\\&h(\vec{x}) = 0  \end{aligned}\right \}
$$
其中：

$$
\begin{aligned} &s({\vec{x}})=[s_1(\vec{x}),...,s_m(\vec{x})]^T\\&h({\vec{x}})=[h_1(\vec{x}),...,h_l(\vec{x})]^T\end{aligned}
$$
在最优化中，常有的术语有：

- $f(\vec{x})$ 称为目标函数。或求它的极小，或求它的极大。
- $s_1(\vec{x})\geq0,...,s_m(\vec{x})\geq0$称为不等式约束。
- $h_1(\vec{x})=0,...,h_l(\vec{x})=0$称为等式约束。
- 满足所有约束的 $\vec{x}$ 称为容许解或容许点。
- 所有容许点的集合称为容许集。

## 二、最优化问题的分类：

<img src="第一章 预备知识/最优化问题分类.png" alt="test" style="zoom:10%;" />

## 三、二维问题的图解法

例题1：用图解法求解无约束极小化问题。

$$
min\ (x_1-2)^2+(x-1)^2
$$
这是定义在 $O_{x_1x_2}$平面 $R^2$上的无约束最优化问题。目标函数为（如图a）：

$$
f(x)=(x_1-2)^2+(x_2-1)^2
$$
过 $f$轴上坐标点为 $f_0$的点作 $O_{x_1x_2}$ 坐标面的平行平面 $L$， $L$ 与曲面 $S$ 可能有一个交点，可能没有交点，也可能交成一条曲线。考虑至少有一个交点的情况，利用平面L去截曲面 $S$ 得到一个圆。将这个圆投影到$O_{x_1x_2}$平面，得到的是同样大小的圆（如图b）。不过这个圆有一个重要的性质，那就是圆上任何一点的目标函数值都等于同一常数，称为目标函数的等值线，如图c。优化问题就转化成在容许区域内找一点，使得等值线对应的目标函数值最小。由图c可知，该问题的解为 $G$ 点，坐标为 $[2,1]^T$。

<img src="第一章 预备知识/例题一图解.jpeg" alt="0EC99227-4164-4030-8B7F-6837BC85D5CB" style="zoom:33%" />

例题2：利用图解法求解约束问题。

$$
\begin{aligned}
&min\ (x_1-2)^2+(x_2-1)^2\\
&s.t.\ x_1+x_2^2-5x_2=0\\ 
&\ \quad\  x_1+x_2-5\geq0\\
&\ \quad \ x_1,x_2\geq0
\end{aligned}
$$
解题步骤如下：

1. 画出目标函数 $f(x)=(x_1-2)^2+(x_2-1)^2$的等值线。
2. 画出约束式 $x_1+x_2^2-5x_2=0$ 的图形，是一条抛物线。
3. 画出不等式约束所代表的区域。

<img src="第一章 预备知识/例题二图解.jpeg" alt="12F8233D-5034-42C4-99FA-107FCAE71C14" style="zoom:33%;" />

不等式约束后容许集的范围缩小成紫色直线右上方的部分，等式约束在等值线图中表现为一条抛物线，经过等式约束的容许集缩小为抛物线上的点。二者叠加，最终的容许集范围是在紫色直线右上方区域内抛物线上的点。

观察抛物线与等值线的交点$A、B、C、D、E$。其中$E$不在不等式约束的范围内，排除。等值线从内到外一次增大。从$A-B$值减少，从$B-C$值增加，从$C-D$一直减少。点$D$是容许集中值使得目标函数值最小的点，故而$D$点即是最优解。

点D坐标可通过求解方程组得到：

$$
\begin{aligned}
&x_1+x_2^2-5x_2=0\\
&x_1+x_2-5=0
\end{aligned}
$$
最优求得最优解为： $x^* = [4,1]^T$ 。

在本例题中$B$点为严格局域最小值，但由于$B$点的目标函数值大于点$D$的目标函数值。所以最优解为点$D$。

## 四、梯度

定义$1.4.1$：设 $f:D \subseteq R^n \rightarrow R^1,x_0 \in D$。如果存在 $n$维向量 $\vec{l}$，对于可以任意小的 $n$ 维非零向量 $\vec{p}$ ，总有：

​          

$$
\lim_{\left \| \vec{p} \right \|   \rightarrow 0} \frac{f(\vec{x_0}-\vec{p})-f(\vec{x_0})-\vec{l}^T\vec{p}}{\left \| \vec{p} \right \| }
$$
那么称函数 $f(\vec{x})$在点 $\vec{x_0}$处可微。

---

定理$1.4.1$：如果函数在$f(\vec{x})$在点$\vec{x_0}$处可微，则$f(\vec{x})$在该点关于各个变量的一阶导数存在，并且

$$
$$l=[\frac{\partial f(x_0)}{\partial x_1}, \frac{\partial f(x_0)}{\partial x_2},..., \frac{\partial f(x_0)}{\partial x_n}]^T
$$

---

定义$1.4.2$：以函数$f(\vec{x})$的$n$个偏导数为分量的向量称为$f(\vec{x})$在点$\vec{x}$处的梯度，记为 $\bigtriangledown f(\vec{x})$ ，即

$$
$$\bigtriangledown f(\vec{x})=[\frac{\partial f(x_0)}{\partial x_1}, \frac{\partial f(x_0)}{\partial x_2},..., \frac{\partial f(x_0)}{\partial x_n}]^T
$$

---

梯度的性质：

- 函数在某点梯度不为零，则它必与函数过该点的等值面垂直。
- 梯度方向是函数具有最大变化率的方向。

梯度方向是函数值的最速上升方向。函数在与其梯度正交的方向上，变化率为零。函数在与其梯度成锐角的方向上，函数值是上升的。而在与其梯度成钝角的方向上，函数值是下降的。

例题：

常用的梯度公式：

- 若$f(x)=C（常数）$，则$\bigtriangledown f(\vec{x})=0$，即$\bigtriangledown C=0$。
- $\bigtriangledown (b^T\vec{x})=b$
- 若Q是对称方阵，则 $\bigtriangledown (\vec{x}^TQ\vec{x})=2Q\vec{x}$。
- $\bigtriangledown (\vec{x}^T\vec{x})=2\vec{x}$

## 五、Hesse矩阵

定义$1.5.1$：设 $\vec{g}:D\subseteq R^n \rightarrow R^m,\vec{x_0} \in D$。如果$\vec{g}(\vec{x})$的所有分量$\vec{g_1}(\vec{x}),...,\vec{g_m}(\vec{x})$在点$\vec{x_0}$都可微，那么称向量值函数$\vec{g}(\vec{x})$在点$\vec{x_0}$处可微。

---

则向量值函数 $\vec{g}(\vec{x})$在点$\vec{x_0}$处的一维导数（梯度）是：

$$
\bigtriangledown \vec{g}(\vec{x_0})=\begin{bmatrix}\frac{\partial \vec{g_1}({\vec{x_0}})}{\partial \vec{x_1}} & \frac{\partial \vec{g_2}({\vec{x_0}})}{\partial \vec{x_1}} & ... & \frac{\partial \vec{g_m}({\vec{x_0}})}{\partial \vec{x_1}}\\  \frac{\partial \vec{g_1}({\vec{x_0}})}{\partial \vec{x_2}}& \frac{\partial \vec{g_2}({\vec{x_0}})}{\partial \vec{x_2}} & ... & \frac{\partial \vec{g_m}({\vec{x_0}})}{\partial \vec{x_2}}\\  ...& ... & ... & ...\\  \frac{\partial \vec{g_1}({\vec{x_0}})}{\partial \vec{x_n}}& \frac{\partial \vec{g_2}({\vec{x_0}})}{\partial \vec{x_n}} & ... & \frac{\partial \vec{g_m}({\vec{x_0}})}{\partial \vec{x_n}} \end{bmatrix}
$$

 $\bigtriangledown \vec{g}(\vec{x0})^T$称为$\vec{g}(\vec{x})$在点$\vec{x_0}$的$jacobi$矩阵。

 

对于具有二阶连续偏导的$n$元函数$f(\vec{x})$，并设$g(\vec{x})=\bigtriangledown f(\vec{x})$，此时$g(\vec{x})$为向量值函数，即：

$$
\vec{g_1}(\vec{x})=\frac{\partial f(\vec{x})}{\partial \vec{x_1}}, \vec{g_2}(\vec{x})=\frac{\partial f(\vec{x})}{\partial \vec{x_2}},..., \vec{g_n}(\vec{x})=\frac{\partial f(\vec{x})}{\partial \vec{x_n}}
$$
此时，$\bigtriangledown \vec{g}(\vec{x})$的$jacobi$矩阵，也就是$f(\vec{x})$的二阶导数为：

$$
$$\bigtriangledown ^2 f(\vec{x})= \bigtriangledown \vec{g}(\vec{x})= \begin{bmatrix}\frac{\partial ^2 f({\vec{x}})}{\partial ^2 \vec{x_1}} & \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_1} \partial \vec{x_2}} & ... & \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_1} \vec{x_n}}\\  \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_2} \partial \vec{x_1}}& \frac{\partial ^2 f({\vec{x}})}{\partial ^2 \vec{x_2}} & ... & \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_2} \partial \vec{x_n}}\\  ...& ... & ... & ...\\  \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_n} \partial \vec{x_1}}& \frac{\partial ^2 f({\vec{x}})}{\partial \vec{x_n} \partial \vec{x_2}} & ... & \frac{\partial ^2 f({\vec{x}})}{\partial ^2 \vec{x_n}} \end{bmatrix}
$$
上述矩阵称为$f(\vec{x})$的$Hesse$矩阵。

常用特殊函数求导公式：

1. $\bigtriangledown \vec{c}=O$ ，其中$\vec{c}$是分量全为常数的$m$维向量，$O$是$n\times m$阶的零矩阵。

2. $\bigtriangledown \vec{x}=I$ ，其中$\vec{x}$是$n$维向量，$I$是$n \times n$阶单位矩阵。

3. $\bigtriangledown (A\vec{x})=A^T$，其中$A$是$n \times m$阶矩阵。

4. $\varphi(\vec{t})=f(\vec{x+0}+\vec{t}\vec{p})$，其中$f:R^n \rightarrow R^1 , \varphi : R^1 \rightarrow R^1$，则：

    $$
    \begin{aligned} &{\varphi}'(\vec{t})= \bigtriangledown f(\vec{x_0}+\vec{t}\vec{p})^T\vec{p}\\&{\varphi}''(\vec{t})= \vec{p}^T \bigtriangledown ^2 f(\vec{x_0}+\vec{t}\vec{p})^T\vec{p} \end{aligned}
    $$

## 六、多元函数的Taylor展开式

定理$1.6.1$：设$f:R^n \rightarrow R^1$具有二阶连续偏导数，则

$$
f(\vec{x}+\vec{p})=f({\vec{x}})+ \bigtriangledown f(\vec{x})^T\vec{p}+\frac{1}{2}\vec{p}^T \bigtriangledown ^2f(\xi)\vec{p}
$$
其中$\xi = \vec{x} + \theta \vec{p}(0 < \theta < 1)$。

---

上述公式也可以表示成：

$$
f(\vec{x}+\vec{p})=f({\vec{x}})+ \bigtriangledown f(\vec{x})^T\vec{p}+\frac{1}{2}\vec{p}^T \bigtriangledown ^2f(\vec{x})\vec{p}+o(\left \| p\right \|^2)
$$

## 七、凸函数与凸规划

### 1.凸集

定义$1.7.1$：设$\vec{x_1},\vec{x_2},...,\vec{x_l}$是$R^n$中的$l$个已知点。对于某点$\vec{x} \in R^n$ ，若存在满足$\Sigma_{i=1}^l \alpha_i=1$的非负实数 $\alpha_1,\alpha_2,...,\alpha_l$使得$\vec{x}=\Sigma_{i=1}^l \alpha_i\vec{x_i}$，则称$\vec{x}$是$\vec{x_1},\vec{x_2},...,\vec{x_l}$的一个凸组合，又若$\alpha_1,\alpha_2,...,\alpha_l$是满足$\Sigma_{i=1}^l \alpha_i=1$的正实数，则称$\vec{x}$是{$\vec{x_1},\vec{x_2},...,\vec{x_l}$的一个严格凸组合。

---

定义$1.7.2$：设集合$C \subseteq R^n$，如果$C$中任意两点的任意凸组合仍然属于$C$，那么集合$C$称为凸集。规定：空集是凸集。

### 2.凸函数

定义$1.7.3$：设$f:C \subseteq R^n \rightarrow R^1$，其中$C$为凸集。若对于$C$中任意互异两点$\vec{x_1},\vec{x_2}$和任意一对满足$\alpha_1 + \alpha_2 = 1$的非负实数 $\alpha_1,\alpha_2$，总有：

$$
f(\alpha_1\vec{x_1}+\alpha_2\vec{x_2})\leq \alpha_1f(\vec{x_1})+\alpha_2f(\vec{x_2})
$$
则称$f$是定义在凸集$C$上的凸函数。

又若对于任意一对满足$\alpha_1 + \alpha_2 =1$的正实数$\alpha_1,\alpha_2$，总有：

$$
f(\alpha_1\vec{x_1}+\alpha_2\vec{x_2})< \alpha_1f(\vec{x_1})+\alpha_2f(\vec{x_2})
$$
则称$f$是定义在凸集$C$上的严格凸函数。

---

凸函数的性质：

1. 若$f$是定义在凸集$C$上的凸函数，$\alpha$是任意的非负实数，则$\alpha f$也是$C$上的凸函数。
2. 若$f_1,f_2$都是定义在凸集$C$上的凸函数，则$f_1+f_2$也是$C$上的凸函数。 

定理$1.7.1$：设$f:C \subseteq R^n \rightarrow R^1$是可微函数，其中$C$为凸集，则：

1. $f$为凸函数的充要条件是对于$C$中任意两点$\vec{x_1},\vec{x_2}$都有：

    $$
    f(\vec{x_2})\geq f(\vec{x_1})+ \bigtriangledown f(\vec{x_1})^T(\vec{x_2}-\vec{x_1})
    $$

2. $f$为严格凸函数的充要条件是对于$C$中任意互异两点$\vec{x_1},\vec{x_2}$都有：

    $$
    f(\vec{x_2})>f(\vec{x_1})+ \bigtriangledown f(\vec{x_1})^T(\vec{x_2}-\vec{x_1})
    $$

---

定理$1.7.2$：设$f:C \subseteq R^n \rightarrow R^1$是二次可微函数，$C$为非空开凸集。则$f$为$C$上凸函数的充要条件是$Hesse$矩阵$\bigtriangledown f(\vec{x})$ 在$C$上处处半正定。

---

定理$1.7.3$：设$f:C \subseteq R^n \rightarrow R^1$是二次可微函数，$C$为非空开凸集。若$f$的$Hesse$矩阵$\bigtriangledown f(\vec{x})$ 在$C$上处处正定，则$f$是$C$上的严格凸函数。

### 3.凸规划

设：$f:C \subseteq R^n \rightarrow R^1$是定义在非空凸集$C$上的凸函数，则形式为：

$$
\left. \begin{aligned} &min\ f(\vec{x})\\&s.t.\ \vec{x} \in C\end{aligned}\right\}\tag{1.7.1}
$$
的最优化问题称为凸规划问题，简称凸规划。换言之，定义在在凸集上的凸函数的极小化问题是凸规划问题。

定义$1.7.4$：$s_1(\vec{x}),s_2(\vec{x}),...,s_m(\vec{x})$都是$R^n$上的凹函数，$h_1{\vec{x}},h_2{\vec{x}},...,h_2{\vec{x}}$都是$R^n$上的线性函数。在这种情况下那么凸规划（1.36）可以表示为：

$$
\left.\begin{aligned}
&min\  f(\vec{x})\\
&s.t.\ s_i(\vec{x})\geq 0\\
&\quad \ \ h_j(\vec{x}=0)
\end{aligned} \right\} \tag{1.7.2}
$$

---

定理$1.7.4$：设是 $\vec{x}^*$ 凸规划（1.7.1）的局部极小点，则：

1.  $\vec{x}^*$是全局极小点。
2. 当$f$是严格凸函数时， $\vec{x}^*$是（1.7.1）唯一的极小点。
3. （1.7.1）的所有全局极小点的集合是凸集。

---

定理$1.7.5$：设$f:C \subseteq R^n \rightarrow R^1$是可微凸函数，$C$为非空凸集，$\vec{x}^* \in C$，则 $\vec{x}^*$是凸规划的极小点的充要条件是对于$C$中的任意一点$\vec{x}$，总有 $\bigtriangledown f(\vec{x}^*)^T(\vec{x}-\vec{x}^*)\geq 0$。

上述定理表明，凸规划在最优点处的任何容许方向都不是下降方向。

---

推论$1.7.1$：设$f:C \subseteq R^n \rightarrow R^1$是可微凸函数，$C$是非空凸集，$\vec{x}^* \in C$。若$\vec{x}^*$使得$\bigtriangledown f(\vec{x}^*)=0$，则$\vec{x}^*$是凸规划的全局极小值点。

### 4.二次函数与二次规划

函数

$$
f(\vec{x})=\frac{1}{2}\vec{x}^TQ\vec{x}+\vec{b}^T\vec{x}=c
$$
称为$n$元二次函数，其中：

$$
Q=\begin{bmatrix}q_{11} &q_{12}  &...  &q_{1n} \\ q_{21} &q_{22}  &...  &q_{2n} \\ ... &...  &...  &... \\ q_{n1}&q_{n2}  &...  &q_{nn} \end{bmatrix},b=\begin{bmatrix}b_1\\ b_2\\ ...\\ b_n\end{bmatrix}
$$
这里的$Q$是对称矩阵。若$Q$是正定的，则(1.1)称为正定二次函数。由于$\bigtriangledown ^2 f(\vec{x})=Q$，正定二次函数是严格凸函数。其最优解为驻点，既$\vec{x}^*=-Q^{-1}\vec{b}$。（$Q$为正定矩阵，逆矩阵一定存在）

形式为：

$$
\left. \begin{aligned}&min\ \frac{1}{2}\vec{x}^TQ\vec{x}+\vec{b}^T\vec{x}=c\\&s.t.\ A\vec{x}\geq\vec{p}\\&\quad \ \ C\vec{x}=\vec{d} \end{aligned} \right \} \tag{1.7.3}
$$
的最优化问题称为二次规划问题，简称二次规划，其中$A$是$m \times n$矩阵，$C$是$l \times n$矩阵。

若$Q$是半正定的或是正定的，则称（1.7.3）为二次凸规划。

定理$1.7.6$：一个$n \times n$对称矩阵$Q$为正定矩阵的充要条件是$Q$的各阶主子式都大于$0$。

## 八、极小点的判定条件

定理$1.8.1$： 设：$f:D \subseteq R^n \rightarrow R^1$具有一阶连续偏导数，$\vec{x}^*$是$D$的内点。若$\vec{x}^*$是$f(\vec{x})$的局部极小点，则：

$$
\bigtriangledown f(\vec{x}^*)=0
$$

---

推论$1.8.2$：设$f:C \subseteq R^n \rightarrow R^1$是可微凸函数，$C$是非空开凸集，$\vec{x}^* \in C$，则$\vec{x}^*$是（1.36）的全局极小点的充要条件是$\bigtriangledown f(\vec{x}^*)=0$。

---

定义$1.8.3$： 设$f:D \subseteq R^n \rightarrow R^1$可微，$\vec{x}^* \in D$。且$\bigtriangledown f(\vec{x}^*)=0$，则$\vec{x}^*$称为$f(\vec{x})$的驻点。

---

定理$1.8.4$：设$f:D \subseteq R^n \rightarrow R^1$具有二阶连续偏导数，$\vec{x}^* \in D$，且$\bigtriangledown f(\vec{x}^*)=0$。若$\bigtriangledown ^2 f(\vec{x}^*)$正定，则$\vec{x}^*$必是$f(\vec{x})$的严格局部极小点。

---

定理$1.8.5$： 设$f:R^n \rightarrow R^1$具有二阶连续偏导数，$\vec{x}^* \in R^n$，且$\bigtriangledown f(\vec{x}^*)=0$。若存在$\vec{x}^*$的$\delta$-邻域$N(\vec{x}^*,\delta)$，使得对于$\forall\  \vec{x} \in N(\vec{x}^*,\delta)$，$\bigtriangledown ^2 f(\vec{x}^*)$都半正定，则$\vec{x}^*$必是$f(\vec{x})$的局部极小点。

## 九、优化算法极有关概念

### 1.下降迭代算法

设第k次迭代点$\vec{x}_k$已求得。若它不满足终止条件，那么该点必存在下降方向$\vec{p}$。对于可微目标函数，即使满足$\bigtriangledown f(\vec{x}_k)^T \vec{p}$的$\vec{p}$。按某种规则选取一个$\vec{p}$，例如$\vec{p}_k$。再沿这个方向适当的向前进一步，即在直线$\vec{x}=\vec{x}_k+t\vec{p}_k$上确定一个新点$\vec{x}_{k+1}=\vec{x}_k+t_k\vec{p}_k$，使得

$$
f(\vec{x}_{k+1})=f(\vec{x}_k+t_k\vec{p}_k)
$$
上述过程称为一次下降迭代过程，$\vec{p}_k$称为搜索（下降）方向，$t_k$称为步长因子。

由于计算机只能进行有限次数的迭代运算，只能得到近似解。因为我们会事先给出精度，当迭代结果满足精度要求时便停止迭代。迭代算法的停止条件称为终止条件，我们在后续章节中会介绍。

在上述迭代过程中，有两个规则需要确定：一个是下降方向$\vec{p}_k$的选取规则，一个是步长因子$t_k$的选取规则。不同的规则对应着不同的最优化方法。

综上所述，无约束问题的基本迭代格式如下：

1. 选定初始点$\vec{x_0}$，置$k=0$。
2. 按某种规则确定下降方向$\vec{p}_k$。
3. 按照某种规则确定$t_k$，使得$f(\vec{x}_k+t_k\vec{p}_k) <f(\vec{x}_k)$。
4. 置$\vec{x}_{k+1}=\vec{x}_k+t_k\vec{p}_k$。
5. 判定$\vec{x}_{k+1}$是否满足终止准则？若满足，迭代终止。否则，置$k=k+1$，转至步骤2。

### 2.直线搜索及其性质

在搜索方向$\vec{p}_k$已经确定的前提下，选择步长因子的方法又很多种，例如选取步长因子为定值等。但在实际计算中，最常用的方法是直线搜索（又称一维搜索），即选取$t_k$使得：

$$
f(\vec{x}_k+t_k\vec{p}_k) =min_t \ f(\vec{x}_k+t\vec{p}_k)
$$
按照这种方法确定的步长因子称为最优步长因子。

为简便起见，用记号：

$$
\vec{z}=ls(x,p) \tag{1.9.1}
$$
表示从点$\vec{x}$出发沿$\vec{p}$方向对目标函数$f(\vec{x})$作直线搜索得到极小值点。

在目标函数f(\vec{x})确定的情况下，($1.9.1$)等价于

$$
\left. \begin{aligned} 
f(\vec{x}+t_0\vec{p})&=min_t\ f(\vec{x}+t\vec{p})\\
\vec{z}&=\vec{x}+t_0\vec{p}
\end{aligned} \right \} \tag{1.9.2}
$$
定理$1.9.1$：设目标函数具有一阶连续偏导数。若$\vec{z}=ls(x,p)$，则

$$
\bigtriangledown f(\vec{z})^T\vec{p}=0
$$

### 3.收敛速度

定义$1.9.1$：对于收敛于$x^*$的序列$\{x_k\}$，若存在一个与$k$无关的实数$\beta$，$\beta \in (0,1)$，使得当$k$从某个$k_0$开始时，总有

$$
\left \|x_{k+1}-x^* \right \|\le \beta \left \|x_{k}-x^* \right \|
$$
则称序列$\{x_k\}$为线性（或一阶）收敛。

---

定义$1.9.2$：对于收敛于$x^*$的序列$\{x_k\}$，若存在与$k$无关的实数$\alpha(\alpha>0)$和$\beta(\beta>0)$，使得当$k$从某个$k_0$开始时，总有

$$
\left \|x_{k+1}-x^* \right \|\le \beta \left \|x_{k}-x^* \right \|^\alpha
$$
则称序列$\{x_k\}$收敛的阶为$\alpha$，或称序列$\{x_k\}$为$\alpha$阶收敛。当$\alpha=2$时，称为二阶收敛，当$1\le\alpha\le2$时，称为超线性收敛。

---

一般来说，线性收敛速度较慢，二阶收敛速度最快，超线性收敛居中。如果一个算法的具有超线性收敛以上的收敛速度，就认为它是一个好的收敛算法。

### 4.计算终止条件

给定精度$\omega_1,\omega_2,\omega_3$。终止条件如下：

1. $\left \|\vec{x}_{k+1}-\vec{x}_k \right \| < \omega_1$
2. $\left \|f(\vec{x}_{k+1})-f(\vec{x}_k) \right \| < \omega_2$
3. $\left \|\bigtriangledown f(\vec{x}_k)\right \| < \omega_3$

上述单一条件无法满足终止收敛的条件，往往是两个或三个终止条件结合来使用，从而判断出是否终止算法。